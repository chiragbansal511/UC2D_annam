{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ffc761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python311\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\python311\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\python311\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python311\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.55.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~%p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~0p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~%p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~0p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~%p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~0p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision matplotlib scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ef518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 1: 100%|██████████| 62/62 [00:44<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 1: Train Acc: 33.09%, Val Acc: 57.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 2: 100%|██████████| 62/62 [00:18<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 2: Train Acc: 64.76%, Val Acc: 71.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 3: 100%|██████████| 62/62 [00:18<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 3: Train Acc: 72.28%, Val Acc: 73.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 4: 100%|██████████| 62/62 [00:18<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 4: Train Acc: 73.45%, Val Acc: 75.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 5: 100%|██████████| 62/62 [00:18<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 5: Train Acc: 76.16%, Val Acc: 77.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 6: 100%|██████████| 62/62 [00:18<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 6: Train Acc: 75.86%, Val Acc: 77.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 7: 100%|██████████| 62/62 [00:18<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 7: Train Acc: 76.98%, Val Acc: 76.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 8: 100%|██████████| 62/62 [00:19<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 8: Train Acc: 76.73%, Val Acc: 77.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 9: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 9: Train Acc: 77.80%, Val Acc: 78.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 10: 100%|██████████| 62/62 [00:18<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 10: Train Acc: 77.90%, Val Acc: 79.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 11: 100%|██████████| 62/62 [00:19<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 11: Train Acc: 78.31%, Val Acc: 79.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 12: 100%|██████████| 62/62 [00:18<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 12: Train Acc: 79.85%, Val Acc: 79.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 13: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 13: Train Acc: 79.69%, Val Acc: 82.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 14: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 14: Train Acc: 79.95%, Val Acc: 82.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 15: 100%|██████████| 62/62 [00:19<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 15: Train Acc: 81.18%, Val Acc: 81.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 16: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 16: Train Acc: 80.72%, Val Acc: 82.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 17: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 17: Train Acc: 80.51%, Val Acc: 82.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 18: 100%|██████████| 62/62 [00:19<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 18: Train Acc: 82.46%, Val Acc: 82.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 19: 100%|██████████| 62/62 [00:18<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 19: Train Acc: 82.56%, Val Acc: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 20: 100%|██████████| 62/62 [00:19<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 20: Train Acc: 82.61%, Val Acc: 81.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 21: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 21: Train Acc: 82.20%, Val Acc: 84.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 22: 100%|██████████| 62/62 [00:19<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 22: Train Acc: 83.12%, Val Acc: 82.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 23: 100%|██████████| 62/62 [00:19<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 23: Train Acc: 83.12%, Val Acc: 84.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 24: 100%|██████████| 62/62 [00:19<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 24: Train Acc: 83.07%, Val Acc: 82.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 25: 100%|██████████| 62/62 [00:19<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 25: Train Acc: 84.09%, Val Acc: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 26: 100%|██████████| 62/62 [00:19<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 26: Train Acc: 84.91%, Val Acc: 84.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 27: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 27: Train Acc: 83.68%, Val Acc: 84.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CustomCNN Epoch 28: 100%|██████████| 62/62 [00:19<00:00,  3.24it/s]\n",
      "c:\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CustomCNN] Epoch 28: Train Acc: 85.37%, Val Acc: 84.25%\n",
      "Early stopping CustomCNN\n",
      "Best Val Acc for CustomCNN: 84.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 1: 100%|██████████| 62/62 [00:22<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 1: Train Acc: 86.70%, Val Acc: 97.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 2: 100%|██████████| 62/62 [00:22<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 2: Train Acc: 95.81%, Val Acc: 97.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 3: 100%|██████████| 62/62 [00:21<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 3: Train Acc: 96.11%, Val Acc: 97.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 4: 100%|██████████| 62/62 [00:22<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 4: Train Acc: 97.54%, Val Acc: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 5: 100%|██████████| 62/62 [00:22<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 5: Train Acc: 97.75%, Val Acc: 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 6: 100%|██████████| 62/62 [00:22<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 6: Train Acc: 97.39%, Val Acc: 99.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 7: 100%|██████████| 62/62 [00:21<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 7: Train Acc: 98.26%, Val Acc: 99.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 8: 100%|██████████| 62/62 [00:21<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 8: Train Acc: 98.82%, Val Acc: 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 9: 100%|██████████| 62/62 [00:21<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 9: Train Acc: 98.77%, Val Acc: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 10: 100%|██████████| 62/62 [00:21<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 10: Train Acc: 99.03%, Val Acc: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MobileNetV2 Epoch 11: 100%|██████████| 62/62 [00:22<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MobileNetV2] Epoch 11: Train Acc: 98.41%, Val Acc: 99.80%\n",
      "Early stopping MobileNetV2\n",
      "Best Val Acc for MobileNetV2: 99.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "ResNet50 Epoch 1: 100%|██████████| 62/62 [00:32<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 1: Train Acc: 90.33%, Val Acc: 98.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 2: 100%|██████████| 62/62 [00:32<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 2: Train Acc: 96.68%, Val Acc: 97.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 3: 100%|██████████| 62/62 [00:32<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 3: Train Acc: 95.96%, Val Acc: 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 4: 100%|██████████| 62/62 [00:32<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 4: Train Acc: 97.08%, Val Acc: 98.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 5: 100%|██████████| 62/62 [00:32<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 5: Train Acc: 98.21%, Val Acc: 99.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 6: 100%|██████████| 62/62 [00:32<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 6: Train Acc: 98.11%, Val Acc: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 7: 100%|██████████| 62/62 [00:32<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 7: Train Acc: 97.03%, Val Acc: 99.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 8: 100%|██████████| 62/62 [00:32<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 8: Train Acc: 98.87%, Val Acc: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 9: 100%|██████████| 62/62 [00:32<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 9: Train Acc: 98.01%, Val Acc: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 10: 100%|██████████| 62/62 [00:32<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 10: Train Acc: 97.80%, Val Acc: 99.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 11: 100%|██████████| 62/62 [00:32<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 11: Train Acc: 97.85%, Val Acc: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 Epoch 12: 100%|██████████| 62/62 [00:31<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet50] Epoch 12: Train Acc: 97.85%, Val Acc: 99.59%\n",
      "Early stopping ResNet50\n",
      "Best Val Acc for ResNet50: 99.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chirag Bansal\\AppData\\Local\\Temp\\ipykernel_33424\\3053452928.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1.load_state_dict(torch.load(\"CustomCNN_best.pth\"))\n",
      "C:\\Users\\Chirag Bansal\\AppData\\Local\\Temp\\ipykernel_33424\\3053452928.py:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load(\"MobileNetV2_best.pth\"))\n",
      "C:\\Users\\Chirag Bansal\\AppData\\Local\\Temp\\ipykernel_33424\\3053452928.py:209: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model3.load_state_dict(torch.load(\"ResNet50_best.pth\"))\n",
      "Predicting Test Set: 100%|██████████| 11/11 [00:06<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to D:\\Projects\\iit_ropar_project\\sample_submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUDA setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Paths\n",
    "TRAIN_DIR = 'D:\\Projects\\iit_ropar_project/train'\n",
    "TEST_DIR = 'D:\\Projects\\iit_ropar_project/test'\n",
    "TRAIN_CSV = 'D:\\Projects\\iit_ropar_project/train_labels.csv'\n",
    "TEST_CSV = 'D:\\Projects\\iit_ropar_project/test_ids.csv'\n",
    "SUBMISSION_CSV = 'D:\\Projects\\iit_ropar_project\\sample_submission.csv'\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 30\n",
    "LABELS = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n",
    "\n",
    "# 🔁 Label Encoding\n",
    "label2idx = {label: i for i, label in enumerate(LABELS)}\n",
    "idx2label = {i: label for label, i in label2idx.items()}\n",
    "\n",
    "# 🧱 Dataset class\n",
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, labels=True, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.has_labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx]['image_id']\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = label2idx[self.df.iloc[idx]['label']]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, img_id\n",
    "\n",
    "# 🔧 Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# 📊 Load train data\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)\n",
    "\n",
    "train_dataset = SoilDataset(train_data, TRAIN_DIR, labels=True, transform=transform)\n",
    "val_dataset = SoilDataset(val_data, TRAIN_DIR, labels=True, transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 🧠 Model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64), nn.ReLU(),\n",
    "            nn.Linear(64, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "def get_model(base='mobilenet'):\n",
    "    if base == 'mobilenet':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n",
    "    elif base == 'resnet':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    return model\n",
    "\n",
    "# 🏋️‍♂️ Train Function\n",
    "def train_model(model, name):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc = 0\n",
    "    patience = 5\n",
    "    stop_counter = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        correct, total = 0, 0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"{name} Epoch {epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        val_acc = evaluate(model)\n",
    "        print(f\"[{name}] Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'{name}_best.pth')\n",
    "            stop_counter = 0\n",
    "        else:\n",
    "            stop_counter += 1\n",
    "            if stop_counter >= patience:\n",
    "                print(f\"Early stopping {name}\")\n",
    "                break\n",
    "\n",
    "    print(f\"Best Val Acc for {name}: {best_acc:.2f}%\")\n",
    "    return model\n",
    "\n",
    "# 📈 Evaluate\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total\n",
    "\n",
    "# 🔮 Predict Test Set\n",
    "def predict_test(models):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    test_dataset = SoilDataset(test_df, TEST_DIR, labels=False, transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    all_preds, all_ids = [], []\n",
    "\n",
    "    with torch.no_grad():  # <--- Add this\n",
    "        for images, img_ids in tqdm(test_loader, desc=\"Predicting Test Set\"):\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Run each model sequentially to avoid memory overflow\n",
    "            outputs = []\n",
    "            for m in models:\n",
    "                m.to(device)\n",
    "                out = m(images)\n",
    "                outputs.append(torch.softmax(out, dim=1))\n",
    "                torch.cuda.empty_cache()  # Clear unused memory\n",
    "\n",
    "            avg_output = sum(outputs) / len(outputs)\n",
    "            preds = torch.argmax(avg_output, dim=1).cpu().numpy()\n",
    "            all_preds.extend([idx2label[i] for i in preds])\n",
    "            all_ids.extend(img_ids)\n",
    "\n",
    "    submission = pd.DataFrame({'image_id': all_ids, 'label': all_preds})\n",
    "    submission.to_csv(SUBMISSION_CSV, index=False)\n",
    "    print(f\"Saved predictions to {SUBMISSION_CSV}\")\n",
    "\n",
    "# 🚀 Main\n",
    "if __name__ == '__main__':\n",
    "    model1 = train_model(CustomCNN(), 'CustomCNN')\n",
    "    model2 = train_model(get_model('mobilenet'), 'MobileNetV2')\n",
    "    model3 = train_model(get_model('resnet'), 'ResNet50')\n",
    "\n",
    "    # Load best models\n",
    "    model1.load_state_dict(torch.load(\"CustomCNN_best.pth\"))\n",
    "    model2.load_state_dict(torch.load(\"MobileNetV2_best.pth\"))\n",
    "    model3.load_state_dict(torch.load(\"ResNet50_best.pth\"))\n",
    "\n",
    "    # Predict and savefepoch\n",
    "    predict_test([model1.to(device), model2.to(device), model3.to(device)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a5f3daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chirag Bansal\\AppData\\Local\\Temp\\ipykernel_2896\\336107337.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1.load_state_dict(torch.load(\"CustomCNN_best.pth\", map_location=device))\n",
      "c:\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Chirag Bansal\\AppData\\Local\\Temp\\ipykernel_2896\\336107337.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load(\"MobileNetV2_best.pth\", map_location=device))\n",
      "C:\\Users\\Chirag Bansal\\AppData\\Local\\Temp\\ipykernel_2896\\336107337.py:117: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model3.load_state_dict(torch.load(\"ResNet50_best.pth\", map_location=device))\n",
      "Predicting Test Set: 100%|██████████| 22/22 [00:20<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to D:/Projects/iit_ropar_project/sample_submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ Setup\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ✅ Paths\n",
    "TEST_DIR = 'D:/Projects/iit_ropar_project/test'\n",
    "TEST_CSV = 'D:/Projects/iit_ropar_project/test_ids.csv'\n",
    "SUBMISSION_CSV = 'D:/Projects/iit_ropar_project/sample_submission.csv'\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16  # Reduced for safety on GPU\n",
    "\n",
    "LABELS = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n",
    "label2idx = {label: i for i, label in enumerate(LABELS)}\n",
    "idx2label = {i: label for label, i in label2idx.items()}\n",
    "\n",
    "# ✅ Dataset Class\n",
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, labels=False, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.has_labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx]['image_id']\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_id\n",
    "\n",
    "# ✅ Transforms\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ✅ Models\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64), nn.ReLU(),\n",
    "            nn.Linear(64, len(LABELS))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "def get_model(base='mobilenet'):\n",
    "    if base == 'mobilenet':\n",
    "        model = models.mobilenet_v2(pretrained=False)\n",
    "        model.classifier[1] = nn.Linear(model.last_channel, len(LABELS))\n",
    "    elif base == 'resnet':\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, len(LABELS))\n",
    "    return model\n",
    "\n",
    "# ✅ Predict Function\n",
    "def predict_test(models):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model.to(device)  # Send to CPU (already set)\n",
    "\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    test_dataset = SoilDataset(test_df, TEST_DIR, labels=False, transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    all_preds, all_ids = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, img_ids in tqdm(test_loader, desc=\"Predicting Test Set\"):\n",
    "            images = images.to(device)\n",
    "            outputs = []\n",
    "            for m in models:\n",
    "                out = m(images)  # All models are already on CPU\n",
    "                outputs.append(torch.softmax(out, dim=1))\n",
    "            avg_output = sum(outputs) / len(outputs)\n",
    "            preds = torch.argmax(avg_output, dim=1).numpy()\n",
    "            all_preds.extend([idx2label[i] for i in preds])\n",
    "            all_ids.extend(img_ids)\n",
    "\n",
    "    submission = pd.DataFrame({'image_id': all_ids, 'label': all_preds})\n",
    "    submission.to_csv(SUBMISSION_CSV, index=False)\n",
    "    print(f\"✅ Saved predictions to {SUBMISSION_CSV}\")\n",
    "\n",
    "# ✅ Run Prediction\n",
    "if __name__ == '__main__':\n",
    "    # Load models and weights\n",
    "    model1 = CustomCNN()\n",
    "    model1.load_state_dict(torch.load(\"CustomCNN_best.pth\", map_location=device))\n",
    "\n",
    "    model2 = get_model('mobilenet')\n",
    "    model2.load_state_dict(torch.load(\"MobileNetV2_best.pth\", map_location=device))\n",
    "\n",
    "    model3 = get_model('resnet')\n",
    "    model3.load_state_dict(torch.load(\"ResNet50_best.pth\", map_location=device))\n",
    "\n",
    "    # Run prediction\n",
    "    predict_test([model1, model2, model3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
